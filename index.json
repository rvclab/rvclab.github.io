
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0be81384651c43872ee50cbae85750f3","permalink":"https://example.com/author/chen-lei/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chen-lei/","section":"authors","summary":"","tags":null,"title":"Chen Lei","type":"authors"},{"authors":null,"categories":null,"content":"I have studied mechanical engineering at both the undergraduate and master’s levels. My current research focuses on non-rigid SLAM and 3D reconstruction. I enjoy playing basketball and weighting lift.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9048eb1e06fcacc326385f0e0c41407b","permalink":"https://example.com/author/haonan-mai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/haonan-mai/","section":"authors","summary":"I have studied mechanical engineering at both the undergraduate and master’s levels. My current research focuses on non-rigid SLAM and 3D reconstruction. I enjoy playing basketball and weighting lift.","tags":null,"title":"Haonan Mai","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2368de8a2a66ad246ecb92ff901ef9a2","permalink":"https://example.com/author/haoyu-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/haoyu-li/","section":"authors","summary":"","tags":null,"title":"Haoyu Li","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0eb2b0ba4b922f30e479a1fc310a5122","permalink":"https://example.com/author/jinke-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jinke-li/","section":"authors","summary":"","tags":null,"title":"Jinke Li","type":"authors"},{"authors":null,"categories":null,"content":"To be edited.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"274a3807fe6062ebbaa188a0efc9dbe7","permalink":"https://example.com/author/leixin-chang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/leixin-chang/","section":"authors","summary":"To be edited.","tags":null,"title":"Leixin Chang","type":"authors"},{"authors":null,"categories":null,"content":"Liangjing Yang is an assistant professor in Zhejiang University/ University of Illinois at Urbana-Champaign (ZJU-UIUC) Institute, where he is appointed as the Vice Director of Research Division for Data and Information Sciences. He is also co-leading the Center for Adaptive, Resilient Cyber-Physical Manufacturing Networks (AR-CyMaN) under the Dynamic Research Enterprise for Multidisciplinary Engineering Sciences (DREMES).\nLiangjing Yang received the B.Eng. and M.Eng. degrees in Mechanical Engineering from theNational University of Singapore (NUS) in 2008 and 2011, respectively. He obtained the D.Eng. degree from the University of Tokyo (UTokyo) in 2014 with a scholarship to work in the Bio-Medical Precision Engineering Laboratory. Before joining ZJU-UIUC Institute, he was with the Singapore University of Technology and Design (SUTD), and Massachusetts Institute of Technology (MIT) under a joint postdoctoral fellowship award.\nLiangjing’s research interests are in Robotics and Computer Vision primarily focusing on biomedical applications including medical image reconstruction and image-guided surgeries. His work in UTokyo on image mapping for 3D ultrasound-guided endoscopic procedures is published in both engineering and medical journals including a self-contained image mapping system presented in Surgical Endoscopy. The work is also recognized by two awards, namely, the Young Investigator Award 2013 from International Society of Computer Aided Surgery and the Best Paper Award in ACCAS 2015 from IEEE-Engineering in Medicine and Biology Society. In NUS, he developed a robotic system for overlapping ablation of large liver tumors, which is featured in a special issue on “Surgical and Interventional Medical Devices” of ASME/IEEE Transactions on Mechatronics. In SUTD and MIT, Liangjing combines his expertise in Robotics and Computer Vision to develop a vision-guided robotic micromanipulation platform, which is published in IEEE Transactions on Automation Science and Engineering including another confidence-based hybrid visual tracking method. He holds two US patents related to an ultrasound image-guided robot and a Robotic Surgical Training System. The former technology is successfully licensed and commercialized while the latter development was named “Best Innovation in Biomedical Application” in a challenge organized by National Instrument in 2011.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"397e83a8c23d5b1e92a46d61b3749b72","permalink":"https://example.com/author/liangjing-yang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/liangjing-yang/","section":"authors","summary":"Liangjing Yang is an assistant professor in Zhejiang University/ University of Illinois at Urbana-Champaign (ZJU-UIUC) Institute, where he is appointed as the Vice Director of Research Division for Data and Information Sciences.","tags":null,"title":"Liangjing Yang","type":"authors"},{"authors":null,"categories":null,"content":"I’m currently a Ph.D. candidate in the Robotics, Vision \u0026amp; Control Lab in the ZJU-UIUC Institute at Zhejiang University, Haining, China, supervised by Professor Liangjing Yang. Before that, I received my B. Eng. degree in Mechanical Engineering from Nanjing University of Aeronautics and Astronautics, Nanjing, China, in 2019. You can find more about me here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"564e7461d6b60acf2f6d7aaa62a3eb6a","permalink":"https://example.com/author/songjie-xiao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/songjie-xiao/","section":"authors","summary":"I’m currently a Ph.D. candidate in the Robotics, Vision \u0026 Control Lab in the ZJU-UIUC Institute at Zhejiang University, Haining, China, supervised by Professor Liangjing Yang. Before that, I received my B.","tags":null,"title":"Songjie Xiao","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"d15ea7b96084c4b2d0f3300c33e024e4","permalink":"https://example.com/author/tengyue-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/tengyue-wang/","section":"authors","summary":"","tags":null,"title":"Tengyue Wang","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"7bfc1912a6b3082673d659dad0d55b5a","permalink":"https://example.com/author/tianle-weng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/tianle-weng/","section":"authors","summary":"","tags":null,"title":"Tianle Weng","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"53d59afa41c0ed44c89e6f3cad1b45c4","permalink":"https://example.com/author/tiexin-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/tiexin-wang/","section":"authors","summary":"","tags":null,"title":"Tiexin Wang","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9271ae8c6f0f9a20164e7ee1a9c34a2f","permalink":"https://example.com/author/wentao-ni/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/wentao-ni/","section":"authors","summary":"","tags":null,"title":"Wentao Ni","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"dacbd09cc08f3862ddbcd4a7fa4c0ae1","permalink":"https://example.com/author/xianhao-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xianhao-chen/","section":"authors","summary":"","tags":null,"title":"Xianhao Chen","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"cb672a0170e061f56930002605c094b8","permalink":"https://example.com/author/yizhou-huang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yizhou-huang/","section":"authors","summary":"","tags":null,"title":"Yizhou Huang","type":"authors"},{"authors":null,"categories":null,"content":"During his undergraduate years, he was ranked first in his major (1/307), won the National Scholarship, Provincial Merit Students, Provincial Outstanding Graduates, Top Ten Outstanding Students of the Year, and a number of national \u0026amp; provincial university students’ scientific and creative competition awards. He likes to make new friends and hopes to make progress through trials and errors.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c3253a1df8821c8bcfcbfd883240c396","permalink":"https://example.com/author/yun-long/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yun-long/","section":"authors","summary":"During his undergraduate years, he was ranked first in his major (1/307), won the National Scholarship, Provincial Merit Students, Provincial Outstanding Graduates, Top Ten Outstanding Students of the Year, and a number of national \u0026 provincial university students’ scientific and creative competition awards.","tags":null,"title":"Yun Long","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"d4fc2b89941da86826d23bd9ef43f231","permalink":"https://example.com/author/yunze-shi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yunze-shi/","section":"authors","summary":"","tags":null,"title":"Yunze Shi","type":"authors"},{"authors":null,"categories":null,"content":"I am in charge of the administration affairs of IRVC Lab. Feel free to contact me for the business related to IRVC Lab.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ebc96f6cd8283de317f59bd38e530714","permalink":"https://example.com/author/yuting-jin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yuting-jin/","section":"authors","summary":"I am in charge of the administration affairs of IRVC Lab. Feel free to contact me for the business related to IRVC Lab.","tags":null,"title":"Yuting Jin","type":"authors"},{"authors":null,"categories":null,"content":"To be edited.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ed9d80e59b0574b882717311f4837586","permalink":"https://example.com/author/zhefan-lin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/zhefan-lin/","section":"authors","summary":"To be edited.","tags":null,"title":"Zhefan Lin","type":"authors"},{"authors":["Yizhou Huang","Songjie Xiao","Yunze Shi","Haoyu Li","Liangjing Yang"],"categories":null,"content":" This conference paper haven’t been published online yet, you can find the PDF file here.\nDownload PDF\n","date":1692921600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692921600,"objectID":"d4823dbc4a9e0278cefe1c8063fcc585","permalink":"https://example.com/publication/yizhouhuang_wrc_2023/","publishdate":"2023-08-25T00:00:00Z","relpermalink":"/publication/yizhouhuang_wrc_2023/","section":"publication","summary":"Compliant control is widely used in the human- robot interaction (HRI) field. However, very few research pays attention on applying compliant control to the pin-based shaped display which is a type of HRI device widely researched as tangible user interface for the enhancement of the HRI quality. Admittance control as one of the compliant controls is performing well under soft environment which is ideal as a candidate control method for pin-based shape display for the reason that the human body surface is generally soft. In this paper, a pin-based shape display with admittance control will be prototyped. The general control scheme as well as the design methodology will be explained and evaluated. A variable compliant control will be proposed and simulated to achieve even normal force distribution on its surface. Different compliant control parameters will be chosen to evaluate the device under experiment.","tags":null,"title":"Application of Compliant control in Pin-Based Shape Display for Compliant Physical Interaction between Human and Machine","type":"publication"},{"authors":["Haoyu Li","Linfei Xiong","Xiaolong Guan","Liangjing Yang"],"categories":null,"content":"","date":1692921600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692921600,"objectID":"368547150f1d3f458aee2b243d0dda21","permalink":"https://example.com/publication/haoyuli_icarm_2023/","publishdate":"2023-08-25T00:00:00Z","relpermalink":"/publication/haoyuli_icarm_2023/","section":"publication","summary":"Microsurgical robots are being extensively researched on to assist surgeons in improving surgical quality. With the exceptionally demanding requirements for precision, coupled with constraining operating space and inevitable hand tremors, surgical instrument manipulation during microsurgeries is challenging. Conventional designs for surgical manipulators have limited flexibility of the RCM point and inadequate versatility. This paper proposes a generalized robotic manipulator for anastomosis and ophthalmic procedures based on a parallelogram structure to mechanically constrain the RCM points. Novel features of the design include the functionality of repositionable RCM point and a quick-change mechanism. Evaluation based on computational analysis and simulation tests confirmed that the design meets the surgical requirements with good operability and safety. We believe that the repositionable RCM capability and the end-effector's quick-change function improve flexibility and operational convenience during microsurgeries.","tags":null,"title":"Design-Centric Model-Based Development of a Generalized Robotic Manipulator for Anastomosis and Ophthalmic Procedures","type":"publication"},{"authors":["Yunze Shi","Tengyue Wang","Jiawei Yu","Songjie Xiao","Linfei Xiong","Liangjing Yang"],"categories":null,"content":"","date":1673049600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673049600,"objectID":"29a01343e132e7fa3e45ca26230a5850","permalink":"https://example.com/publication/yunzeshi_vpf_hr_teleop/","publishdate":"2023-01-07T00:00:00Z","relpermalink":"/publication/yunzeshi_vpf_hr_teleop/","section":"publication","summary":"Driven by the evolving role of modern robots in collaboration with human operators, this paper proposes a virtual potential field-based motion planning and control strategy to realize effective human-robot collaboration through kinesthetic guidance via robot teleoperation. The motion of the teleoperated robot is determined by the human operator using a haptic device programmed to replicate movement under the influence of the virtual potential field constructed based on the obstacles and objectives in the environment. This approach facilitates seamless cooperation between the human and collaborative robot. It can also be readily generalized to include moving obstacles and goals in a dynamic environment. The results suggest that the virtual potential field can effectively enhance the safety and accuracy of human-robot cooperation. The developed method has promising applications in human-centric robotics fields such as medical robotics and robot-assisted surgeries.","tags":null,"title":"Virtual Potential Field-Based Motion Planning for Human-Robot Collaboration via Kinesthetically Guided Teleoperation","type":"publication"},{"authors":null,"categories":null,"content":" Introduction:\n","date":1670716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670716800,"objectID":"f76491d9f442f56bfcb5edeed8912ad1","permalink":"https://example.com/projects/img_map_framework_us_procedure/","publishdate":"2022-12-11T00:00:00Z","relpermalink":"/projects/img_map_framework_us_procedure/","section":"projects","summary":"","tags":null,"title":"Image Mapping Framework for Ultrasound-Guided Procedures","type":"projects"},{"authors":null,"categories":null,"content":" Introduction:\n","date":1670716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670716800,"objectID":"144c4c33dbdddb8c4cdc0fdfc32da5a0","permalink":"https://example.com/projects/img_guided_sur_train_sys/","publishdate":"2022-12-11T00:00:00Z","relpermalink":"/projects/img_guided_sur_train_sys/","section":"projects","summary":"","tags":null,"title":"Image-guided Surgical Training System: A Robotic System that Learn and Teach","type":"projects"},{"authors":null,"categories":null,"content":"Congratulations to Tiexin Wang, Zheyu Wu, Tanghu Pu and Haoyu Li for winning second prize in 2022 First MedBot® Robotic Innovation Contest!\nThe organizing committee of the 2022 First MedBot® Robotic “Da Mai Cup” Geek Innovation Contest awarded second prize to PU Tanhong, LI Haoyu, master students of Mechanical Engineering of ZJUI, class of 2021, WANG Tiexin, doctoral student of ZJUI, class of 2020, and WU Zheyu, ZJUI undergraduate, class of 2022. With Liangjing YANG, Assistant Professor and researcher at ZJUI, serving as the team leader, the project entitled“MR-based Visual System for Cellular micromanipulation” applied mixed reality technology (MR technology) to real-time cellular operation through system construction. Thisvisualization of the operation processbrings+new insight into cell operation experimentation and enables Precision Medicine.\n","date":1670716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670716800,"objectID":"da5954b37c6d38aded2f6b6cadd8610a","permalink":"https://example.com/post/mr_medrobot_award/","publishdate":"2022-12-11T00:00:00Z","relpermalink":"/post/mr_medrobot_award/","section":"post","summary":"Congratulations to Tiexin Wang, Zheyu Wu, Tanghu Pu and Haoyu Li for winning second prize in 2022 First MedBot® Robotic Innovation Contest!\n","tags":null,"title":"MR Empowers Precision Medicine，RVC Team Wins Second Prize in 2022 First MedBot® Robotic Innovation Contest!","type":"post"},{"authors":null,"categories":null,"content":" Introduction:\n","date":1670716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670716800,"objectID":"c6790bdb44ffc2a1169c8e1394064aee","permalink":"https://example.com/projects/robotic_ar_sys_mini_inv_sur/","publishdate":"2022-12-11T00:00:00Z","relpermalink":"/projects/robotic_ar_sys_mini_inv_sur/","section":"projects","summary":"","tags":null,"title":"Robotic Augmented Reality System for Minimally Invasive Surgery","type":"projects"},{"authors":null,"categories":null,"content":" Introduction:\n","date":1670716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670716800,"objectID":"e56ed5ec02e3d0bc9ab7498bd7bba684","permalink":"https://example.com/projects/vision_guided_robotic_micromanipulation/","publishdate":"2022-12-11T00:00:00Z","relpermalink":"/projects/vision_guided_robotic_micromanipulation/","section":"projects","summary":"","tags":null,"title":"Vision-Guided Robotic Micromanipulation Platform","type":"projects"},{"authors":["Tiexin Wang","Haoyu Li","Tanhong Pu","Jingjing Ding","Shoukang Du","Zhong Hoo Chau","U-Xuan Tan","Ting Gang Chew","Liangjing Yang"],"categories":null,"content":"","date":1666915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666915200,"objectID":"ae01b0f1c2989631a751f0641e9bc1a5","permalink":"https://example.com/publication/tiexin_self_recalibration_case/","publishdate":"2022-10-28T00:00:00Z","relpermalink":"/publication/tiexin_self_recalibration_case/","section":"publication","summary":"A self-recalibrating micromanipulator system is proposed in this study for resilient robotic vision-based control. The system can achieve self-calibration in complex backgrounds. Self-calibrated tracking failures are detected and rectified through the self-recalibration scheme. In the experiment, the BSTM method during the self-calibration process achieves accurate tracking with a mean error of less than 1 pixel (0.18 μm). And the system can achieve high control accuracy after self-calibration in complex backgrounds, with an average control error of 4.18 pixels (0.75 μm), which satisfies the accuracy requirements of cell aspiration experiments. In addition, the system achieved stable tracking under complex operating environments such as cell interaction, occlusion, tip leaving the focal plane or beyond the field-of-view.","tags":null,"title":"Self-Recalibrating Micromanipulator System for Resilient Robotic Vision-Based Control","type":"publication"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://example.com/contact/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://example.com/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"","date":1665360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665360000,"objectID":"34751dc521b4cccf7f292ceafd34ce1f","permalink":"https://example.com/teaching_source/advanced-robotics/","publishdate":"2022-10-10T00:00:00Z","relpermalink":"/teaching_source/advanced-robotics/","section":"teaching_source","summary":"","tags":null,"title":"Advanced Robotics (2023 Spring)","type":"landing"},{"authors":null,"categories":null,"content":"","date":1665360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665360000,"objectID":"4a9432f09685355a0c11089ec58e5e97","permalink":"https://example.com/hiring/","publishdate":"2022-10-10T00:00:00Z","relpermalink":"/hiring/","section":"","summary":"","tags":null,"title":"Hiring","type":"landing"},{"authors":null,"categories":null,"content":"","date":1665360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665360000,"objectID":"7e0e2af5e3593b54061214e7db586af1","permalink":"https://example.com/teaching_source/modern_control_system/","publishdate":"2022-10-10T00:00:00Z","relpermalink":"/teaching_source/modern_control_system/","section":"teaching_source","summary":"","tags":null,"title":"Modern Control System (2022 Fall)","type":"landing"},{"authors":["Jiawei Yu","Tengyue Wang","Zhenyu Zong","Liangjing Yang"],"categories":null,"content":"","date":1660953600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660953600,"objectID":"96f0468dcfe303a6fd4a5007d3e42ab9","permalink":"https://example.com/publication/jiaweiyu-_immersive_wrc_2022/","publishdate":"2022-08-20T00:00:00Z","relpermalink":"/publication/jiaweiyu-_immersive_wrc_2022/","section":"publication","summary":"Interaction between humans and robots is inevitable in robotic surgeries. The purpose of this work is to enhance human-robot interaction for computer-assisted minimally invasive surgeries through immersive technology. Our developed system includes a robotic manipulator designed to perform minimally invasive surgeries and a mixed reality-based interface that facilitates immersive interaction between a human operator and a collaborative robot. The system provides visual and dexterous augmentation through the immersive projection of the endoscopic view in proximity to the surgical site and a virtual remote-center-of-motion (RCM) intuitively specified by the users. Experimental observation demonstrated sub-millimeter and sub-degree accuracy between the spatial representation of the physical robot and its virtual model. Safety design and robot intelligence to enhance the interaction between humans and robots via MR technology will further be developed to prepare the technology for actual clinical use in the long run.","tags":null,"title":"Immersive Human-Robot Interaction for Dexterous Manipulation in Minimally Invasive Procedures","type":"publication"},{"authors":["Hsieh-Yu Li","Yuchen Ma","M. Naufal A. Bin Miswadi","Long Nguyen Nguyen Luu","Liangjing Yang"],"categories":null,"content":"","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654041600,"objectID":"12535cd0f789e55c7377be7e6813b696","permalink":"https://example.com/publication/hsiheyuli_detect_remove_place/","publishdate":"2022-06-01T00:00:00Z","relpermalink":"/publication/hsiheyuli_detect_remove_place/","section":"publication","summary":"Fused filament fabrication (FFF) 3D printing is one of the most common additive processes due to its low cost and speed of production. There has been growing interest to have a fleet of such printers, which can be procured at low cost, as they have enormous potential of providing a large volume of continuous production of customized parts on demand. However, the main bottleneck for the FFF printing process is that the part must be manually removed before the next print can commence as the print bed is occupied. Time is also wasted when erroneous print is not stopped. This requirement increases the downtime of the machines significantly, which affects utilization and profit. The process is desired by several industries for continuous printing around the clock. Therefore, this article presents a system with vision-based failure detection and robotic manipulation, termed detect-remove-replace ( DRR ), to address the aforementioned issues. It provides automated monitoring and part extraction for FFF 3D printers while eliminating the need for manual intervention to enable unmanned continuous printing. The experimental results show that DRR is able to detect common defects of the prints (such as spaghetti, detachment, and air printing) with 85.11% accuracy. In addition, the prints are successfully removed 20 times out of 21 tests, and the heatbed steel sheet is robustly replaced for the next prints with a 100% success rate.","tags":null,"title":"Detect-Remove-Replace: A Robotic Solution That Enables Unmanned Continuous 3D Printing","type":"publication"},{"authors":["Jiawei Yu","Tengyue Wang","Yunze Shi","Liangjing Yang"],"categories":null,"content":"","date":1646006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646006400,"objectID":"6081817002b78ae8e01ee1d6bdd4f6b7","permalink":"https://example.com/publication/jiaweiyu_mr_meet_robotics/","publishdate":"2022-02-28T00:00:00Z","relpermalink":"/publication/jiaweiyu_mr_meet_robotics/","section":"publication","summary":"The rising interest in Mixed Reality (MR) technology in robotics and the lack of prior work in the literature of this subject motivate this review paper. Our purpose is to discuss current research and the advancement of MR applications in the context of robotics. Development in modern robots towards a more human-centric role is driven largely by enabling technology including, but not limited to, machine vision, cobots, virtual reality, and more recently, MR technology. The scope encompasses MR technology in various aspects of robotics, namely, robot vision, control and planning, human-robot interaction, multi-user collaborations, and swarm robotics. Through discussions of the benefits and knowledge gaps in contemporary development, the review is expected to provide readers with an in-depth appreciation of the state-of-the-art technology and the possibility of MR technology in robotics.","tags":null,"title":"MR Meets Robotics: A Review of Mixed Reality Technology in Robotics","type":"publication"},{"authors":["Yuding Wang","Ting Gang Chew","Liangjing Yang"],"categories":null,"content":"","date":1636070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636070400,"objectID":"7fe512be69b730021ae300c739b19350","permalink":"https://example.com/publication/yudingwang_2021_embc/","publishdate":"2021-11-05T00:00:00Z","relpermalink":"/publication/yudingwang_2021_embc/","section":"publication","summary":"Cell morphological analysis has great impact towards our understanding of cell biology. It is however technically challenging to acquire the complete process of cell cycles under microscope inspection. Using convolutional long short-term memory (ConvLSTM) networks, this paper proposes a comprehensive visualization method for cell cycles by retro-reconstruction of the preceding frames that are not captured. Results suggested that this method has the potential to overcome existing technical bottlenecks in image acquisition of cellular process and hence facilitate cell analysis.Clinical Relevance— This model allows back-tracing to complete the visualization of the cellular processes through a short segment of microscope-acquired cellular changes hence providing a starting point for exploring applications in predicting or backtracking unknown cellular processes.","tags":null,"title":"A Preliminary Study on Retro-reconstruction of Cell Fission Dynamic Process using Convolutional LSTM Neural Networks","type":"publication"},{"authors":["Yucheng Jin","Xiaomeng yang","Chenting Yu","Liangjing Yang"],"categories":null,"content":"","date":1634256000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634256000,"objectID":"8ff05c121a86c02524a5d5e680959ef2","permalink":"https://example.com/publication/yuchengjin_2021_bdet/","publishdate":"2021-10-15T00:00:00Z","relpermalink":"/publication/yuchengjin_2021_bdet/","section":"publication","summary":"The past decades have witnessed the vigorous development of new technologies in the educational field, among which Educational Data Mining (EDM) played an indispensable role in pedagogical improvement, enabling researchers to discover useful knowledge from education-oriented databases. By clustering student-related and parents-related variables into three categories: demographic and family background information (Demographic), self-perceived willingness for education (Willingness), perceived family interaction (Interaction) and utilizing various EDM methodologies such as linear regression, regression tree, random forest, and neural network, this study is the first attempt to conduct a comprehensive and quantitative investigation into the principal factors that influence Chinese junior high school students’ academic performance on a nationally representative survey, the China Education Panel Survey (CEPS) dataset. Additionally, this study further summarizes, explains, and compares different principal factors discovered by different EDM techniques, and proposes two practical strategies for mitigating China's educational inequality.","tags":null,"title":"Educational Data Mining: Discovering Principal Factors for Better Academic Performance","type":"publication"},{"authors":["Songjie Xiao","Chaojun Wang","Yunze Shi","Jiawei Yu","Linfei Xiong","Chengzhong Peng","Liangjing Yang"],"categories":null,"content":"","date":1631318400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631318400,"objectID":"3881af1f4cc882a4051736ec35c899a1","permalink":"https://example.com/publication/songjiexiao_2021_wrc/","publishdate":"2021-09-11T00:00:00Z","relpermalink":"/publication/songjiexiao_2021_wrc/","section":"publication","summary":"Ultrasonography is one of the most common intraoperative imaging modalities for image-guided procedures in clinical practice. However, the quality of the ultrasound image depends largely on the skill and dexterity of the surgeon. We propose a robotic control system for intraoperative ultrasound imaging that optimizes visual quality of the ultrasonography using variable impedance control for regulating the contact force of the ultrasound transducer. The system consists of a human-robot-environment interaction (HREI) system and a needle insertion system. Experimental results show that the HREI system can control the robot in collaboration with the human while interacting with the environment and maintain a constant force with a maximum error of 0.2N. These results support the feasibility of our proposed approach. This study has the potential to positively impact current practices in ultrasound image-guided procedures.","tags":null,"title":"Visual Optimization of Ultrasound-Guided Robot-Assisted Procedures Using Variable Impedance Control","type":"publication"},{"authors":["Hsieh-Yu Li","Ishara Paranawithana","Liangjing Yang","U-Xuan Tan"],"categories":null,"content":"","date":1629158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629158400,"objectID":"f1b83ceef1b5b1ea4346f619ef3d3691","permalink":"https://example.com/publication/hsiehyuli_variable-admittance_control/","publishdate":"2021-08-17T00:00:00Z","relpermalink":"/publication/hsiehyuli_variable-admittance_control/","section":"publication","summary":"In the field of collaborative robot whose end-effector is complaint in response to human force, the human operator is able to execute tasks based on their judgement. The advantages include human power augmentation and utilization of human's judgement. A force/torque sensor is usually mounted on the end -effector to sense the human force, which is sent to an interaction controller to yield velocity command for the robot to follow. However, when human guides the end-effector to contact an extra dynamic environment that moves in multiple directions, it poses challenges on controller design. The interaction controller needs to provide the stable interaction for human operator to contact such a dynamic contact force (due to the moving environment) while to provide compliant cooperation for the human to follow the motion of the environment. To address these issues, we propose variable admittance control based on robust adaptive velocity control. The human and environmental forces are considered in the variable admittance controller to obtain the suitable interaction between robot, human, and environment. Additionally, robust adaptive control is employed to enhance the tracking performance. Experiments are conducted and the results show the proposed controller enables the human operator to stably contact a dynamic environment and compliantly track the motion of it.","tags":null,"title":"Variable Admittance Control with Robust Adaptive Velocity Control for Dynamic Physical Interaction between Robot, Human and Environment","type":"publication"},{"authors":["Anqi Tan","Shenwei Chen","Hanyu Gan","Liangjing Yang"],"categories":null,"content":"","date":1625270400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625270400,"objectID":"9535ea5067f647f402c7a36786fdc013","permalink":"https://example.com/publication/anqitan_opt_mech_rcm/","publishdate":"2021-07-03T00:00:00Z","relpermalink":"/publication/anqitan_opt_mech_rcm/","section":"publication","summary":"This paper presents a novel RCM mechanism, which contains a parallel manipulator and a parallelogram structure to create a re-localizable RCM point that can be generalized over a range of procedures.","tags":null,"title":"Design Optimization of a Mechanically Constrained Re-Localizable Remote-Center-of-Motion","type":"publication"},{"authors":["Yinan Pei","Tianyi Han","Christopher M. Zallek","Tao Liu","Liangjing Yang","Elizabeth T. Hsiao-Wecksler"],"categories":null,"content":"","date":1615420800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615420800,"objectID":"1063b541c8b68d3f7fb3ae434fd52deb","permalink":"https://example.com/publication/yinanpei_sea_ankle/","publishdate":"2021-03-11T00:00:00Z","relpermalink":"/publication/yinanpei_sea_ankle/","section":"publication","summary":"To fulfill the need for reliable and consistent medical training of the neurological examination technique to assess ankle clonus, a series elastic actuator (SEA) based haptic training simulator was proposed and developed. The simulator's mechanism (a hybrid of belt and linkage drive) and controller (impedance control) were designed to render a realistic and safe training environment. Benchtop tests demonstrated that the prototype simulator was able to accurately estimate the interaction torque from the trainee (average RMSE of 0.2 Nm) and closely track a chirp torque command up to 10 Hz (average RMSE of \u003c0.22 Nm). The high-level impedance controller could switch between different clinically encountered states (i.e., no clonus, unsustained clonus, and sustained clonus) based on trainee's assessment technique. The simulator was evaluated by a group of 17 experienced physicians and physical therapists. Subjects were instructed to induce sustained clonus using their normal technique. The simulator was assessed in two common clinical positions (seated and supine). Subjects scored simulation realism on a variety of control features. To expedite controller design iteration, feedback from Day 1 was used to modify simulation parameters prior to testing on Day 2 with a new subject group. On average, all subjects could successfully trigger a sustained clonus response within 4-5 attempts in the first position and 2-3 in the second. Feedback on the fidelity of simulation realism improved between Day 1 and Day 2. Results suggest that this SEA-based simulator could be a viable training tool for healthcare trainees learning to assess ankle clonus.","tags":null,"title":"Design and Clinical Validation of a Robotic Ankle-Foot Simulator With Series Elastic Actuator for Ankle Clonus Assessment Training","type":"publication"},{"authors":["Yunze Shi","Santosh Kumar Singh","Liangjing Yang"],"categories":null,"content":"","date":1614297600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614297600,"objectID":"aa0e3f0841a78c108ab0a4cf084f8999","permalink":"https://example.com/publication/yunzeshi_control_strategies_review/","publishdate":"2021-02-26T00:00:00Z","relpermalink":"/publication/yunzeshi_control_strategies_review/","section":"publication","summary":"With the increasing demand for soft and smart robotic technology for surgical applications, there have been growing interests in the development of controllers. Modern developments in the design process of surgical robots are being fundamentally different from traditional robots. There is a huge design gap with a lack of a unified and systematic framework for the design process, analysis, and control for these high-dimensional robots. On the other hand, more and more surgical robots have been developed, which has greatly impacted medical practice. This review paper attempts to provide an insight into various control strategies such as PID control, model predictive control, and sliding mode control along with basic structures of different autonomy level surgical robot control systems as a guideline for the clinical application of surgical robot in the futures. A comprehensive assessment by highlighting the limitations and design gaps of various control strategies is reported for future application.","tags":null,"title":"Classical Control Strategies Used in Recent Surgical Robots","type":"publication"},{"authors":["Santosh Kumar Singh","Liangjing Yang","Hao Ma"],"categories":null,"content":"","date":1614297600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614297600,"objectID":"1249a2ee9f06276992c0ea0751c9e104","permalink":"https://example.com/publication/liangjingyang_haptic_interface_surgical_review/","publishdate":"2021-02-26T00:00:00Z","relpermalink":"/publication/liangjingyang_haptic_interface_surgical_review/","section":"publication","summary":"Enhancement in the efficiency of surgical proficiency training system requires a continuous effort in surgical care atmosphere without any risk factor and it is known as a complex and challenging task nowadays. The process is exclusively relevant in training of technical skills specific to modern Minimally Invasive System (MIS) based procedures like keyhole surgery. However, modern surgical training systems are more intensive on the improvement of technical skills for dexterity, imagining and accurateness of the surgeons which are lacking in aspects of context-awareness and intra-operative real-time supervision. Context-aware intelligent training systems interpret the modern surgical condition and help surgeons to train on surgical tasks. Motivated by the development aspects and needs, this paper presents in depth review and highlights of the major challenging factors for haptic control interfacing, which are required to overcome in the future development of intelligent and highly integrated surgical training system for robotic surgery","tags":null,"title":"Recent challenges for haptic interface and control for robotic assisted surgical training system: A review","type":"publication"},{"authors":["Liangjing Yang","Kobayashi Etsuko"],"categories":null,"content":"","date":1599523200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599523200,"objectID":"93e4e59f5e5a58adccd083ae5e0492ff","permalink":"https://example.com/publication/liangjingyang_vision_tracking_review/","publishdate":"2020-09-08T00:00:00Z","relpermalink":"/publication/liangjingyang_vision_tracking_review/","section":"publication","summary":"Computer vision is an important cornerstone for the foundation of many modern technologies. The development of modern computer-aided-surgery, especially in the context of surgical navigation for minimally invasive surgery, is one example. Surgical navigation provides the necessary spatial information in computer-aided-surgery. Amongst the various forms of perception, vision-based sensing has been proposed as a promising candidate for tracking and localisation application largely due to its ability to provide timely intra-operative feedback and contactless sensing. The motivation for vision-based sensing in surgical navigation stems from many factors, including the challenges faced by other forms of navigation systems. A common surgical navigation system performs tracking of surgical tools with external tracking systems, which may suffer from both technical and usability issues. Vision-based tracking offers a relatively streamlined framework compared to those approaches implemented with external tracking systems. This review study aims to discuss contemporary research and development in vision-based sensing for surgical navigation. The selected review materials are expected to provide a comprehensive appreciation of state-of-the-art technology and technical issues enabling holistic discussions of the challenges and knowledge gaps in contemporary development. Original views on the significance and development prospect of vision-based sensing in surgical navigation are presented.","tags":null,"title":"Review on vision‐based tracking in surgical navigation","type":"publication"},{"authors":["Hsieh-Yu Li","Liangjing Yang","U-Xuan Tan"],"categories":null,"content":"","date":1595203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595203200,"objectID":"13d380cd2995ee834dac289f95ec1758","permalink":"https://example.com/publication/hsiehyuli_control_smooth_transition/","publishdate":"2020-07-20T00:00:00Z","relpermalink":"/publication/hsiehyuli_control_smooth_transition/","section":"publication","summary":"There has been an increasing demand for physical human-robot collaboration during the design prototyping phase. For example, users would like to maneuver the end-effector compliantly in free space followed by supplying a contact force to obtain a firm adhesive connection. The technical challenges is the design of the controller, especially during the switching from human-robot interaction (human guides robot) to robot-environment interaction for the robot to continuously maintain the contact force even after the human lets go. Traditional controllers often result in unstable interaction during the switches of the controllers. Therefore, this letter proposes a control scheme that unifies impedance and admittance in the outer loop, and unifies the adaptive position and velocity control in the inner loop to address this issue. The cooperation of the cobot is divided into two modes, namely, an augmentation mode where the human force is the desired input to guide the motion of the cobot, and an autonomous mode where predefined position and force commands are used (e.g., to maintain a desired holding force). With the proposed control scheme, the physical interaction between the robot, human and environment can be smoothly and stably transited from augmentation mode to autonomous mode. Experiments are then conducted to validate the proposed approach.","tags":null,"title":"A control scheme for smooth transition in physical human-robot-environment between two modes: Augmentation and autonomous","type":"publication"},{"authors":["Zhong Hoo Chau","Liangjing Yang","Zhong Chen","Kamal Youcef-Toumi","U-Xuan Tan"],"categories":null,"content":"","date":1594944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594944000,"objectID":"a08320511e3de57f63b2f4711049f4bd","permalink":"https://example.com/publication/zhonghoochau_cell_target/","publishdate":"2020-07-17T00:00:00Z","relpermalink":"/publication/zhonghoochau_cell_target/","section":"publication","summary":"There is an increasing demand for uncalibrated micromanipulation systems for its capability to perform on-site microscopic applications. An example is the auto targeting of plant cells for applications such as injection or extraction of chloroplasts. In addition, uncalibrated micromanipulation approach will also save the tedious calibration effort that is required when a new tool or specimen is loaded. Hence, this paper proposes a method to perform automated multiple-cell targeting in a plant cell array through an uncalibrated vision-based micromanipulation system. An improved version of watershed segmentation technique coupled with generalized cell sizing algorithm is first proposed to detect the centroid of the plant cells, without the usual need of staining. A self-focusing algorithm is also used to detect and focus either the plant cell array or the micropipette tip, or both. The method is then combined with uncalibrated tool focusing and visual track-servo algorithms to manipulate the micropipette. Experiment has been conducted and the proposed method has been tested on a waterweed. The results illustrates the capability of the uncalibrated detection and targeting of multiple plant cells.","tags":null,"title":"Cell Targeting of Plant Cells Array using Uncalibrated Vision-Based Approac","type":"publication"},{"authors":["Hsieh-Yu Li","Audelia G. Dharmawan","Ishara Paranawithana1","Liangjing Yang","U-Xuan Tan1"],"categories":null,"content":"","date":1570406400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570406400,"objectID":"e3ff5c3c4b398eb33490338e27dfea8d","permalink":"https://example.com/publication/hsiehyuli_control_unknown_stiffness/","publishdate":"2019-10-07T00:00:00Z","relpermalink":"/publication/hsiehyuli_control_unknown_stiffness/","section":"publication","summary":"Variable admittance control is commonly used for a collaborative robot to achieve the compliant or accurate cooperation according to human’s intention. However, existing research seldom investigates such a human-robot collaboration coupled with an extra environment with unknown stiffness. If the end-effector that is guided by a human with various intended motion contacts the unknown environment, the interaction might become unstable. Additionally, current research for this physical human-robot-environment interaction use two force sensors to address the issue, and hence the cost of the robot is likely to increase and it reduces the flexibility to many applications. Therefore, in this paper, we address the issue of physical human- robot interaction coupled with an extra environment whose stiffness is unknown. To achieve this, the condition of robot admittance is rigorously proved in accordance with different human intended motion and environmental stiffness. Moreover, a variable admittance control scheme is proposed based on human intention, environmental force and environment stiffness using the combination of a force sensor and a force observer. Simulation and experiments are conducted to demonstrate the effectiveness of the proposed control scheme.","tags":null,"title":"A Control Scheme for Physical Human-Robot Interaction Coupled with an Environment of Unknown Stiffness","type":"publication"},{"authors":["J Huang","X Li","T Kesavadas","L Yang"],"categories":null,"content":"","date":1564099200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564099200,"objectID":"2a305ad5e448cb45bb42a86e37b213cd","permalink":"https://example.com/publication/jhuang_feature_tracking/","publishdate":"2019-07-26T00:00:00Z","relpermalink":"/publication/jhuang_feature_tracking/","section":"publication","summary":"The strong interest in data-driven surgical procedures has motivated the need for automatically analyzing instrument trajectories during surgical procedures to improve the efficacy of modern robot-assisted surgeries. We proposed a single view camera-based approach for automatic video analysis of surgical instruments during robot-assisted minimally invasive procedures. This video data-driven approach uses feature extraction for visual tracking of the surgical instrument, coupled with the kinematics of the pivoted motion in minimally invasive surgery for tool trajectory analysis. The self-contained nature of the approach enables the acquisition of trajectory information without any prior placement of markers or post storage of robot joint trajectories information. Based on visual inspection of the 2D localization results in the image frames, the proposed method demonstrated reasonable recovery of the 3D positional information of the surgical tools. Driven by the increasingly sophisticated interventional procedures of modern surgeries, this proposed trajectory tracking method provides a means for leveraging the wealth of surgical video data for data analytics in Surgical Data Science. The long-term goal of the study is to contribute towards the advancement of Surgical Data Science through the establishment of a video-based data acquisition technique.","tags":null,"title":"Feature Extraction of Video Data for Automatic Visual Tool Tracking in Robot Assisted Surgery","type":"publication"},{"authors":["Kaiwen Hong","Yue Sun","Jiale He","Yong Lei","Lianging Yang"],"categories":null,"content":"","date":1548201600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548201600,"objectID":"fd9b55a2e97f902237a9e4f2d061aa0b","permalink":"https://example.com/publication/kaiwenhong_kinaesthetic/","publishdate":"2019-01-23T00:00:00Z","relpermalink":"/publication/kaiwenhong_kinaesthetic/","section":"publication","summary":"This study aims to develop a robotic system human–machine interaction (HMI) to facilitate surgical training through visual and kinaesthetic feedbacks. This is motivated by the pressing need for effective surgical training and the unaddressed gaps in existing surgical training simulator for minimally invasive procedures. This study establishes the design concept and scope for development to facilitate the required HMI training model. Subsequently, implementation and demonstration of the model is carried out with analytical experiments to assess the feasibility of the proposed concept. The design concept of the robotic system for training is demonstrated through an user experiment. Results suggest viability and observable benefits in the authors’ proposed kinaesthetic HMI guidance for the trainee. Potential impact of this study includes the development of a novel training paradigm that engages trainees through collaborative training facilitated by human trainers and active kinaesthetic simulation. Although motivated by surgical training applications, the concept developed in this study can potentially be extended for general motor skill learning.","tags":null,"title":"Preliminary design of a robotic system for kinaesthetic training of surgical tasks","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"322dbaccf72a6d71f827fdb2866be935","permalink":"https://example.com/teaching/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/teaching/","section":"","summary":"","tags":null,"title":"Teaching","type":"landing"}]